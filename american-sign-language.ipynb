{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6110c45",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.072203Z",
     "iopub.status.busy": "2023-07-05T02:46:54.071729Z",
     "iopub.status.idle": "2023-07-05T02:46:54.086262Z",
     "shell.execute_reply": "2023-07-05T02:46:54.085346Z"
    },
    "papermill": {
     "duration": 0.023819,
     "end_time": "2023-07-05T02:46:54.088782",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.064963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "def print_input_files():\n",
    "    import os\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cc20b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.098680Z",
     "iopub.status.busy": "2023-07-05T02:46:54.098322Z",
     "iopub.status.idle": "2023-07-05T02:46:54.104861Z",
     "shell.execute_reply": "2023-07-05T02:46:54.103806Z"
    },
    "papermill": {
     "duration": 0.013663,
     "end_time": "2023-07-05T02:46:54.106727",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.093064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, train_file_path, base_folder_path):\n",
    "        if base_folder_path.endswith(\"/\"):\n",
    "            self.base_folder_path = base_folder_path\n",
    "        else:\n",
    "            self.base_folder_path = base_foldder_path + \"/\"\n",
    "        \n",
    "        self.train_data = pd.read_csv(train_file_path)\n",
    "        self.relevant_data = None\n",
    "        self.pq_path = None\n",
    "        \n",
    "    def get_relevant_data_subset(self, pq_path, sequence_id):\n",
    "        if pq_path == self.pq_path:\n",
    "            return self.relevant_data.loc[sequence_id]\n",
    "        \n",
    "        self.relevant_data = pd.read_parquet(base_folder_path + pq_path)\n",
    "        self.pq_path = pq_path\n",
    "        return self.relevant_data.loc[sequence_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06344a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.118110Z",
     "iopub.status.busy": "2023-07-05T02:46:54.117059Z",
     "iopub.status.idle": "2023-07-05T02:46:54.263736Z",
     "shell.execute_reply": "2023-07-05T02:46:54.262944Z"
    },
    "papermill": {
     "duration": 0.155286,
     "end_time": "2023-07-05T02:46:54.266131",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.110845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_folder_path = \"/kaggle/input/asl-fingerspelling/\"\n",
    "train_file_path = \"/kaggle/input/asl-fingerspelling/train.csv\"\n",
    "dataset = Dataset(train_file_path, base_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab88c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.276799Z",
     "iopub.status.busy": "2023-07-05T02:46:54.275352Z",
     "iopub.status.idle": "2023-07-05T02:46:54.282219Z",
     "shell.execute_reply": "2023-07-05T02:46:54.281552Z"
    },
    "papermill": {
     "duration": 0.014122,
     "end_time": "2023-07-05T02:46:54.284288",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.270166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_frame_frequency():    \n",
    "    total_frames = 0\n",
    "    total_output_size = 0\n",
    "    for pq_path, sequence_id, output in zip(dataset.train_data['path'], dataset.train_data['sequence_id'], dataset.train_data['phrase']):\n",
    "        relevant_data = dataset.get_relevant_data_subset(pq_path, sequence_id)\n",
    "        total_frames += len(relevant_data)\n",
    "        total_output_size += len(output)\n",
    "\n",
    "    print(total_frames)\n",
    "    print(total_output_size)\n",
    "    print(\"Average frames per character: {}\".format(total_frames / total_output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10611eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.294049Z",
     "iopub.status.busy": "2023-07-05T02:46:54.293720Z",
     "iopub.status.idle": "2023-07-05T02:46:54.383085Z",
     "shell.execute_reply": "2023-07-05T02:46:54.381991Z"
    },
    "papermill": {
     "duration": 0.097378,
     "end_time": "2023-07-05T02:46:54.385785",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.288407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "counter = Counter(''.join(dataset.train_data['phrase']))    \n",
    "most_common_character = counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6207a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.395730Z",
     "iopub.status.busy": "2023-07-05T02:46:54.395373Z",
     "iopub.status.idle": "2023-07-05T02:46:54.399279Z",
     "shell.execute_reply": "2023-07-05T02:46:54.398346Z"
    },
    "papermill": {
     "duration": 0.011342,
     "end_time": "2023-07-05T02:46:54.401338",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.389996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Load character map\n",
    "# 2. Initialize weights so that it always map to most common character\n",
    "# 3. Build model\n",
    "# 4. Convert into TFLite\n",
    "# 5. Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bab3e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.411434Z",
     "iopub.status.busy": "2023-07-05T02:46:54.410624Z",
     "iopub.status.idle": "2023-07-05T02:46:54.420787Z",
     "shell.execute_reply": "2023-07-05T02:46:54.419662Z"
    },
    "papermill": {
     "duration": 0.017663,
     "end_time": "2023-07-05T02:46:54.422944",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.405281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "    character_map = json.load(f)\n",
    "rev_character_map = {j:i for i,j in character_map.items()}\n",
    "\n",
    "print(len(rev_character_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ce7eb",
   "metadata": {
    "papermill": {
     "duration": 0.003764,
     "end_time": "2023-07-05T02:46:54.432413",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.428649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Apparently we are not given a video but rather 3D coordinates of the different points of the body, probably for hiding sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf85576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:46:54.442027Z",
     "iopub.status.busy": "2023-07-05T02:46:54.441416Z",
     "iopub.status.idle": "2023-07-05T02:47:02.671765Z",
     "shell.execute_reply": "2023-07-05T02:47:02.670701Z"
    },
    "papermill": {
     "duration": 8.238035,
     "end_time": "2023-07-05T02:47:02.674373",
     "exception": false,
     "start_time": "2023-07-05T02:46:54.436338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_model():\n",
    "    # Given the input and output size\n",
    "    output_size = len(rev_character_map)\n",
    "    input_size = dataset.get_relevant_data_subset(dataset.train_data.iloc[0]['path'], dataset.train_data.iloc[0]['sequence_id']).shape[1]\n",
    "    \n",
    "    # Build model\n",
    "    input_layer = layers.Input(shape=(input_size,), name=\"inputs\")\n",
    "    nan_to_zero = layers.Lambda(\n",
    "        lambda x: tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), name=\"nan_to_zero\")(input_layer)\n",
    "    output_layer = layers.Dense(output_size, name='outputs')(nan_to_zero)\n",
    "    \n",
    "    # Create the Dense layer\n",
    "    dense_layer = layers.Dense(output_size, trainable=False, name='outputs')\n",
    "\n",
    "    # Calculate weights\n",
    "    weights = np.zeros((input_size, output_size))\n",
    "    bias = np.zeros((output_size,))\n",
    "    bias[character_map[most_common_character]] = 1\n",
    "\n",
    "    # Set weights\n",
    "    dense_layer.build((None, input_size))\n",
    "    dense_layer.set_weights([weights, bias])\n",
    "\n",
    "    # Call the layer passing the input tensor\n",
    "    output_layer = dense_layer(nan_to_zero)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    # Compile and return\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b1809c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:47:02.684504Z",
     "iopub.status.busy": "2023-07-05T02:47:02.683842Z",
     "iopub.status.idle": "2023-07-05T02:47:21.056101Z",
     "shell.execute_reply": "2023-07-05T02:47:21.054983Z"
    },
    "papermill": {
     "duration": 18.380183,
     "end_time": "2023-07-05T02:47:21.058927",
     "exception": false,
     "start_time": "2023-07-05T02:47:02.678744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af89027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:47:21.069212Z",
     "iopub.status.busy": "2023-07-05T02:47:21.068840Z",
     "iopub.status.idle": "2023-07-05T02:47:21.089497Z",
     "shell.execute_reply": "2023-07-05T02:47:21.088126Z"
    },
    "papermill": {
     "duration": 0.028187,
     "end_time": "2023-07-05T02:47:21.091571",
     "exception": false,
     "start_time": "2023-07-05T02:47:21.063384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1630)]            0         \n",
      "                                                                 \n",
      " nan_to_zero (Lambda)        (None, 1630)              0         \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 59)                96229     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,229\n",
      "Trainable params: 0\n",
      "Non-trainable params: 96,229\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9afbef8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:47:21.103406Z",
     "iopub.status.busy": "2023-07-05T02:47:21.102985Z",
     "iopub.status.idle": "2023-07-05T02:47:21.111501Z",
     "shell.execute_reply": "2023-07-05T02:47:21.110373Z"
    },
    "papermill": {
     "duration": 0.017193,
     "end_time": "2023-07-05T02:47:21.113912",
     "exception": false,
     "start_time": "2023-07-05T02:47:21.096719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    frames = dataset.get_relevant_data_subset(dataset.train_data.iloc[0]['path'], dataset.train_data.iloc[0]['sequence_id'])\n",
    "\n",
    "    REQUIRED_SIGNATURE = \"serving_default\"\n",
    "    REQUIRED_OUTPUT = \"outputs\"\n",
    "\n",
    "    with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n",
    "        character_map = json.load(f)\n",
    "    rev_character_map = {j:i for i,j in character_map.items()}\n",
    "\n",
    "    found_signatures = list(model.get_signature_list().keys())\n",
    "\n",
    "    if REQUIRED_SIGNATURE not in found_signatures:\n",
    "        raise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "    prediction_fn = model.get_signature_runner(\"serving_default\")\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
    "    return prediction_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80a13707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:47:21.126231Z",
     "iopub.status.busy": "2023-07-05T02:47:21.125823Z",
     "iopub.status.idle": "2023-07-05T02:47:22.194580Z",
     "shell.execute_reply": "2023-07-05T02:47:22.193380Z"
    },
    "papermill": {
     "duration": 1.077881,
     "end_time": "2023-07-05T02:47:22.196985",
     "exception": false,
     "start_time": "2023-07-05T02:47:21.119104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.tflite (deflated 100%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r submission.zip model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7e69669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T02:47:22.209844Z",
     "iopub.status.busy": "2023-07-05T02:47:22.208977Z",
     "iopub.status.idle": "2023-07-05T02:47:22.218514Z",
     "shell.execute_reply": "2023-07-05T02:47:22.217470Z"
    },
    "papermill": {
     "duration": 0.018579,
     "end_time": "2023-07-05T02:47:22.220903",
     "exception": false,
     "start_time": "2023-07-05T02:47:22.202324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Equivalent of how the model is evaluated\n",
    "\n",
    "def evaluate_model_src():\n",
    "    model_path = \"/kaggle/working/model.tflite\"\n",
    "    frames = dataset.get_relevant_data_subset(dataset.train_data.iloc[0]['path'], dataset.train_data.iloc[0]['sequence_id'])\n",
    "\n",
    "    import tflite_runtime.interpreter as tflite\n",
    "    interpreter = tflite.Interpreter(model_path)\n",
    "\n",
    "    REQUIRED_SIGNATURE = \"serving_default\"\n",
    "    REQUIRED_OUTPUT = \"outputs\"\n",
    "\n",
    "    with open (\"/kaggle/input/fingerspelling-character-map/character_to_prediction_index.json\", \"r\") as f:\n",
    "        character_map = json.load(f)\n",
    "    rev_character_map = {j:i for i,j in character_map.items()}\n",
    "\n",
    "    found_signatures = list(interpreter.get_signature_list().keys())\n",
    "\n",
    "    if REQUIRED_SIGNATURE not in found_signatures:\n",
    "        raise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "    prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n",
    "    return prediction_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f8df2",
   "metadata": {
    "papermill": {
     "duration": 0.004965,
     "end_time": "2023-07-05T02:47:22.231764",
     "exception": false,
     "start_time": "2023-07-05T02:47:22.226799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.494707,
   "end_time": "2023-07-05T02:47:25.727278",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-05T02:46:44.232571",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
