{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-23T22:55:53.722297Z","iopub.execute_input":"2023-06-23T22:55:53.722704Z","iopub.status.idle":"2023-06-23T22:55:53.747334Z","shell.execute_reply.started":"2023-06-23T22:55:53.722670Z","shell.execute_reply":"2023-06-23T22:55:53.746578Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/glovetwitter27b/glove.twitter.27B.200d.txt\n/kaggle/input/glovetwitter27b/glove.twitter.27B.25d.txt\n/kaggle/input/glovetwitter27b/glove.twitter.27B.50d.txt\n/kaggle/input/glovetwitter27b/glove.twitter.27B.100d.txt\n/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/disaster-tweets-text-embeddings/test_text_embeddings.csv\n/kaggle/input/disaster-tweets-text-embeddings/train_text_embeddings.csv\n/kaggle/input/disaster-tweets-chatgpt-output/chatgpt_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:55:55.194787Z","iopub.execute_input":"2023-06-23T22:55:55.195150Z","iopub.status.idle":"2023-06-23T22:56:09.618294Z","shell.execute_reply.started":"2023-06-23T22:55:55.195122Z","shell.execute_reply":"2023-06-23T22:56:09.617142Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai) (2.28.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.64.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai) (3.8.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: openai\nSuccessfully installed openai-0.27.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.data.path.append('/kaggle/working')\nnltk.download(\"wordnet\", download_dir='/kaggle/working')\n\nimport os\nos.environ['NLTK_DATA'] = '/kaggle/working'\n\n!mkdir /kaggle/working/corpora/wordnet\n!unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:56:16.100775Z","iopub.execute_input":"2023-06-23T22:56:16.101183Z","iopub.status.idle":"2023-06-23T22:56:20.020911Z","shell.execute_reply.started":"2023-06-23T22:56:16.101144Z","shell.execute_reply":"2023-06-23T22:56:20.019600Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working...\nArchive:  /kaggle/working/corpora/wordnet.zip\n  inflating: /kaggle/working/corpora/wordnet/lexnames  \n  inflating: /kaggle/working/corpora/wordnet/data.verb  \n  inflating: /kaggle/working/corpora/wordnet/index.adv  \n  inflating: /kaggle/working/corpora/wordnet/adv.exc  \n  inflating: /kaggle/working/corpora/wordnet/index.verb  \n  inflating: /kaggle/working/corpora/wordnet/cntlist.rev  \n  inflating: /kaggle/working/corpora/wordnet/data.adj  \n  inflating: /kaggle/working/corpora/wordnet/index.adj  \n  inflating: /kaggle/working/corpora/wordnet/LICENSE  \n  inflating: /kaggle/working/corpora/wordnet/citation.bib  \n  inflating: /kaggle/working/corpora/wordnet/noun.exc  \n  inflating: /kaggle/working/corpora/wordnet/verb.exc  \n  inflating: /kaggle/working/corpora/wordnet/README  \n  inflating: /kaggle/working/corpora/wordnet/index.sense  \n  inflating: /kaggle/working/corpora/wordnet/data.noun  \n  inflating: /kaggle/working/corpora/wordnet/data.adv  \n  inflating: /kaggle/working/corpora/wordnet/index.noun  \n  inflating: /kaggle/working/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"train_file_path = \"/kaggle/input/nlp-getting-started/train.csv\"\ntrain_data = pd.read_csv(train_file_path)\n\nprint(train_data.columns)\n\ntest_file_path = \"/kaggle/input/nlp-getting-started/test.csv\"\ntest_data = pd.read_csv(test_file_path)\n\nprint(test_data.columns)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:56:24.106461Z","iopub.execute_input":"2023-06-23T22:56:24.106901Z","iopub.status.idle":"2023-06-23T22:56:24.194507Z","shell.execute_reply.started":"2023-06-23T22:56:24.106867Z","shell.execute_reply":"2023-06-23T22:56:24.193655Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\nIndex(['id', 'keyword', 'location', 'text'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport os\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom openai.embeddings_utils import get_embedding\n\n# Class responsible for handling the input data\nclass Dataset:\n    learn_len = None\n    \n    combined_data = None\n    train_data = None\n    test_data = None\n    learn_data = None\n    assess_data = None\n    \n    train_target_data = None\n    learn_target_data = None\n    assess_target_data = None\n    \n    combined_encoded_text = None\n    train_encoded_text = None\n    test_encoded_text = None\n    learn_encoded_text = None\n    assess_encoded_text = None\n    \n    combined_sequences = None\n    train_sequences = None\n    test_sequences = None\n    learn_sequences = None\n    assess_sequences = None\n    \n    vocab_size = None\n    tokenizer = None\n    max_sequence_length = 28\n    \n    train_embeddings_read_file_path = \"/kaggle/input/disaster-tweets-text-embeddings/train_text_embeddings.csv\"\n    test_embeddings_read_file_path = \"/kaggle/input/disaster-tweets-text-embeddings/test_text_embeddings.csv\"\n    train_embeddings_file_path = \"/kaggle/working/train_text_embeddings.csv\"\n    test_embeddings_file_path = \"/kaggle/working/test_text_embeddings.csv\"\n    combined_text_embeddings = None\n    train_text_embeddings = None\n    test_text_embeddings = None\n    learn_text_embeddings = None\n    assess_text_embeddings = None\n\n    # data is pandas DataFrame\n    def __init__(self, train_data, test_data, learn_ratio, assess_ratio):\n        assert learn_ratio + assess_ratio == 1, \\\n        \"The sum of learn_ratio and assess_ratio should be equal to 1\"\n        \n        self.train_data = train_data\n        self.test_data = test_data\n        self.learn_len = int(learn_ratio * len(self.train_data))\n        self.learn_data  = self.train_data.iloc[:self.learn_len]\n        self.assess_data = self.train_data.iloc[self.learn_len:]\n        self.combined_data = pd.concat([self.train_data.iloc[:, :-1], self.test_data])\n        \n        self.train_target_data = self.train_data.iloc[:, -1]\n        self.learn_target_data = self.train_target_data[:self.learn_len]\n        self.assess_target_data = self.train_target_data[self.learn_len:]\n        \n        self.tokenizer = Tokenizer()\n        self.tokenizer.fit_on_texts(self.combined_data['text'])\n        self.vocab_size = len(self.tokenizer.word_index) + 1\n\n        self.create_sequences()\n        self.create_encoded_texts()\n        self.create_text_embeddings()\n        \n    def create_sequences(self):\n        self.combined_sequences = pad_sequences(\n            self.tokenizer.texts_to_sequences(self.combined_data['text']), \n            maxlen=self.max_sequence_length, \n            padding='post')\n        self.train_sequences = pad_sequences(\n            self.tokenizer.texts_to_sequences(self.train_data['text']),\n            maxlen=self.max_sequence_length,\n            padding='post')\n        self.test_sequences = pad_sequences(\n            self.tokenizer.texts_to_sequences(self.test_data['text']),\n            maxlen=self.max_sequence_length,\n            padding='post')\n        self.learn_sequences = pad_sequences(\n            self.tokenizer.texts_to_sequences(self.learn_data['text']),\n            maxlen=self.max_sequence_length,\n            padding='post')\n        self.assess_sequences = pad_sequences(\n            self.tokenizer.texts_to_sequences(self.assess_data['text']),\n            maxlen=self.max_sequence_length,\n            padding='post')\n        \n    def create_encoded_texts(self):\n        encoded_documents = self.tfidf_encode_documents(self.combined_data['text'])\n        self.combined_encoded_text = pd.DataFrame.sparse.from_spmatrix(encoded_documents)\n        self.train_encoded_text = self.combined_encoded_text.iloc[:len(self.train_data)]\n        self.test_encoded_text = self.combined_encoded_text.iloc[len(self.train_data):]\n        self.learn_data_encoded_text = self.train_encoded_text[:self.learn_len]\n        self.assess_data_encoded_text = self.train_encoded_text[self.learn_len:]\n        \n    def create_text_embeddings(self):\n        if self.try_to_load_embeddings():\n            print(\"Successfully loaded text embeddings from local storage !\")\n            return\n        else:\n            print(\"Failed to load text embeddings from local storage ... \")\n            self.generate_embeddings()\n            self.save_embeddings()\n            \n    def lemmatize(self, text):\n        words = re.findall(r'\\w+', text.lower())\n        lemmatizer = WordNetLemmatizer()\n        return [lemmatizer.lemmatize(word) for word in words]\n    \n    def tfidf_encode_documents(self, documents):\n        vectorizer = TfidfVectorizer(tokenizer = self.lemmatize)\n        return vectorizer.fit_transform(documents)\n    \n    def try_to_load_embeddings(self):\n        if self.try_to_read_embeddings(self.train_embeddings_file_path, self.test_embeddings_file_path) or \\\n                self.try_to_read_embeddings(self.train_embeddings_read_file_path, self.test_embeddings_read_file_path):\n            self.combined_text_embeddings = pd.concat([self.train_text_embeddings, self.test_text_embeddings])\n            self.learn_text_embeddings = self.train_text_embeddings[:self.learn_len]\n            self.assess_text_embeddings = self.train_text_embeddings[self.learn_len:]\n            return True\n        return False\n    \n    def try_to_read_embeddings(self, train_file_path, test_file_path):\n        if os.path.exists(train_file_path) and os.path.exists(test_file_path):\n            self.train_text_embeddings = pd.read_csv(train_file_path)\n            self.test_text_embeddings = pd.read_csv(test_file_path)\n            return True\n        return False\n    \n    def generate_embeddings(self, model=\"text-embedding-ada-002\"):\n        print(\"Generating embeddings using OpenAI API ... \")\n        self.combined_text_embeddings = pd.DataFrame(self.combined_data.text.apply(\n            lambda x: get_embedding(x.replace(\"\\n\", \" \"), engine=model)).tolist())\n        self.train_text_embeddings = self.combined_text_embeddings.iloc[:len(self.train_data)]\n        self.test_text_embeddings = self.combined_text_embeddings.iloc[len(self.train_data):]\n        self.learn_text_embeddings = self.train_text_embeddings.iloc[:self.learn_len]\n        self.assess_text_embeddings = self.train_text_embeddings.iloc[self.learn_len:]\n        print(\"Generated embeddings using OpenAI API ... \")\n\n    def save_embeddings(self):\n        print(\"Savings embeddings to local storage ... \")\n        self.train_text_embeddings.to_csv(self.train_embeddings_file_path)\n        self.test_text_embeddings.to_csv(self.test_embeddings_file_path)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:56:41.040016Z","iopub.execute_input":"2023-06-23T22:56:41.040393Z","iopub.status.idle":"2023-06-23T22:56:50.247875Z","shell.execute_reply.started":"2023-06-23T22:56:41.040364Z","shell.execute_reply":"2023-06-23T22:56:50.246945Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = Dataset(train_data, test_data, 0.8, 0.2)\n\nassert len(dataset.learn_data) + len(dataset.assess_data) == len(dataset.train_data), \\\n\"The size of the learn_data and assess_data should total to the size of data\"\n\nprint(\"Learn dataset len={}\".format(len(dataset.learn_data)))\nprint(\"Assess dataset len={}\".format(len(dataset.assess_data)))\nprint(\"Total dataset len={}\".format(len(dataset.train_data)))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:57:07.171911Z","iopub.execute_input":"2023-06-23T22:57:07.172338Z","iopub.status.idle":"2023-06-23T22:57:26.835421Z","shell.execute_reply.started":"2023-06-23T22:57:07.172305Z","shell.execute_reply":"2023-06-23T22:57:26.834426Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Successfully loaded text embeddings from local storage !\nLearn dataset len=6090\nAssess dataset len=1523\nTotal dataset len=7613\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset.combined_text_embeddings.shape)\nprint(dataset.train_text_embeddings.shape)\nprint(dataset.test_text_embeddings.shape)\nprint(dataset.learn_text_embeddings.shape)\nprint(dataset.assess_text_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:57:29.414395Z","iopub.execute_input":"2023-06-23T22:57:29.414792Z","iopub.status.idle":"2023-06-23T22:57:29.421401Z","shell.execute_reply.started":"2023-06-23T22:57:29.414763Z","shell.execute_reply":"2023-06-23T22:57:29.420012Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(10876, 1537)\n(7613, 1537)\n(3263, 1537)\n(6090, 1537)\n(1523, 1537)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Neural Network model\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\ninput_size = dataset.train_encoded_text.shape[1]\nhidden_layer_size = 10\n\ntfidf_model = keras.models.Sequential()\ntfidf_model.add(keras.layers.Dense(hidden_layer_size, activation='swish', input_shape=(input_size,)))\ntfidf_model.add(keras.layers.Dense(2, activation='softmax'))\ntfidf_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\ntfidf_model.fit(dataset.train_encoded_text, dataset.train_target_data, epochs = 10)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:57:32.901951Z","iopub.execute_input":"2023-06-23T22:57:32.902833Z","iopub.status.idle":"2023-06-23T22:57:55.276610Z","shell.execute_reply.started":"2023-06-23T22:57:32.902794Z","shell.execute_reply":"2023-06-23T22:57:55.274501Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Num GPUs Available:  0\nEpoch 1/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.6394 - accuracy: 0.6511\nEpoch 2/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.4677 - accuracy: 0.8375\nEpoch 3/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.3340 - accuracy: 0.8874\nEpoch 4/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.2471 - accuracy: 0.9192\nEpoch 5/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.1854 - accuracy: 0.9409\nEpoch 6/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.1395 - accuracy: 0.9580\nEpoch 7/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.1063 - accuracy: 0.9718\nEpoch 8/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.0817 - accuracy: 0.9808\nEpoch 9/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.0638 - accuracy: 0.9863\nEpoch 10/10\n238/238 [==============================] - 2s 7ms/step - loss: 0.0507 - accuracy: 0.9899\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79ba068e37c0>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport collections\n\ndef load_glove_model(file_path, size, verbose = 1):\n    model = collections.defaultdict(lambda: np.array([0.0 for _ in range(size)]))\n    with open(file_path) as f:\n        for line in f:\n            tokens = line.split(' ')\n            word = tokens[0]\n            embeddings = np.array([float(value) for value in tokens[1:]])\n            model[word] = embeddings\n    if verbose >= 1:\n        print(\"Words loaded!\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:57:59.103814Z","iopub.execute_input":"2023-06-23T22:57:59.104198Z","iopub.status.idle":"2023-06-23T22:57:59.111730Z","shell.execute_reply.started":"2023-06-23T22:57:59.104169Z","shell.execute_reply":"2023-06-23T22:57:59.110729Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Read the GloVe with pandas\nimport numpy as np\n\nembedding_size = 100\nglove_file_path = \"/kaggle/input/glovetwitter27b/glove.twitter.27B.100d.txt\"\nglove_embeddings = load_glove_model(glove_file_path, embedding_size)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:58:00.689680Z","iopub.execute_input":"2023-06-23T22:58:00.690093Z","iopub.status.idle":"2023-06-23T22:58:53.618441Z","shell.execute_reply.started":"2023-06-23T22:58:00.690062Z","shell.execute_reply":"2023-06-23T22:58:53.617304Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Words loaded!\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nfrom tensorflow.keras.initializers import Constant\nimport numpy as np\n\nprint(dataset.vocab_size)\nembedding_matrix = np.zeros((dataset.vocab_size, embedding_size))\nfor word, i in dataset.tokenizer.word_index.items():\n    embedding_matrix[i] = glove_embeddings[word]\n    \nembedding_model = Sequential()\nembedding_layer = Embedding(\n    dataset.vocab_size,\n    embedding_size,\n    embeddings_initializer=Constant(embedding_matrix),\n    input_length=dataset.max_sequence_length,\n    trainable=False)\nembedding_model.add(embedding_layer)\nembedding_model.add(LSTM(100))\nembedding_model.add(Dense(2, activation='softmax'))\nembedding_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nembedding_model.fit(dataset.train_sequences, dataset.train_target_data, epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T22:58:57.272629Z","iopub.execute_input":"2023-06-23T22:58:57.272990Z","iopub.status.idle":"2023-06-23T23:00:47.442375Z","shell.execute_reply.started":"2023-06-23T22:58:57.272963Z","shell.execute_reply":"2023-06-23T23:00:47.441579Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"29320\nEpoch 1/20\n238/238 [==============================] - 8s 22ms/step - loss: 0.4789 - accuracy: 0.7767\nEpoch 2/20\n238/238 [==============================] - 6s 23ms/step - loss: 0.4224 - accuracy: 0.8182\nEpoch 3/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.4069 - accuracy: 0.8245\nEpoch 4/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.3850 - accuracy: 0.8354\nEpoch 5/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.3791 - accuracy: 0.8400\nEpoch 6/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.3584 - accuracy: 0.8526\nEpoch 7/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.3393 - accuracy: 0.8609\nEpoch 8/20\n238/238 [==============================] - 6s 23ms/step - loss: 0.3168 - accuracy: 0.8738\nEpoch 9/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.3000 - accuracy: 0.8799\nEpoch 10/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.2794 - accuracy: 0.8893\nEpoch 11/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.2604 - accuracy: 0.8998\nEpoch 12/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.2343 - accuracy: 0.9121\nEpoch 13/20\n238/238 [==============================] - 5s 23ms/step - loss: 0.2165 - accuracy: 0.9200\nEpoch 14/20\n238/238 [==============================] - 6s 23ms/step - loss: 0.1975 - accuracy: 0.9274\nEpoch 15/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.1713 - accuracy: 0.9389\nEpoch 16/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.1529 - accuracy: 0.9451\nEpoch 17/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.1384 - accuracy: 0.9485\nEpoch 18/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.1245 - accuracy: 0.9557\nEpoch 19/20\n238/238 [==============================] - 5s 22ms/step - loss: 0.1197 - accuracy: 0.9570\nEpoch 20/20\n238/238 [==============================] - 6s 23ms/step - loss: 0.1030 - accuracy: 0.9651\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79b99f63ae90>"},"metadata":{}}]},{"cell_type":"code","source":"# Neural Network model\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\nprint(dataset.test_text_embeddings)\n\ninput_size = dataset.train_text_embeddings.shape[1]\nhidden_layer_size = 10\n\nopenai_model = keras.models.Sequential()\nopenai_model.add(keras.layers.Dense(hidden_layer_size, activation='swish', input_shape=(input_size,)))\nopenai_model.add(keras.layers.Dense(2, activation='softmax'))\nopenai_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nopenai_model.fit(dataset.train_text_embeddings, dataset.train_target_data, epochs = 200)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:54:49.330960Z","iopub.execute_input":"2023-06-23T19:54:49.331344Z","iopub.status.idle":"2023-06-23T19:57:11.991725Z","shell.execute_reply.started":"2023-06-23T19:54:49.331314Z","shell.execute_reply":"2023-06-23T19:57:11.990260Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Num GPUs Available:  0\n      Unnamed: 0         0         1         2         3         4         5  \\\n0           7613 -0.021635  0.008594  0.009741  0.003018 -0.026378  0.011286   \n1           7614 -0.002266 -0.001679  0.021356 -0.014359  0.002140  0.009852   \n2           7615 -0.025502 -0.008412 -0.014390  0.005832 -0.020620  0.023935   \n3           7616 -0.010744 -0.013325 -0.012183  0.004142 -0.024717  0.009615   \n4           7617  0.003850 -0.018499  0.005596  0.017528 -0.012945  0.008153   \n...          ...       ...       ...       ...       ...       ...       ...   \n3258       10871 -0.005213 -0.010868 -0.000101 -0.029862 -0.000932 -0.002580   \n3259       10872 -0.023784 -0.007963 -0.018151  0.011523 -0.007818  0.012971   \n3260       10873 -0.009089 -0.008814  0.016513 -0.018191 -0.026394  0.014942   \n3261       10874 -0.013321  0.005856 -0.016371 -0.018341 -0.008559  0.016996   \n3262       10875 -0.007721 -0.030153 -0.022838 -0.016321 -0.016713  0.025137   \n\n             6         7         8  ...      1526      1527      1528  \\\n0    -0.008286  0.002644 -0.015880  ...  0.009357 -0.022199  0.028787   \n1    -0.008064 -0.015451  0.022839  ...  0.003957  0.002689  0.028484   \n2    -0.007965 -0.007693 -0.006081  ...  0.014739  0.007668 -0.003413   \n3     0.009027 -0.007311  0.031650  ... -0.003585 -0.014338  0.003357   \n4    -0.025051 -0.007188  0.006709  ...  0.017554  0.003261  0.019759   \n...        ...       ...       ...  ...       ...       ...       ...   \n3258 -0.018818 -0.017639  0.033005  ... -0.002612 -0.018144  0.047234   \n3259  0.004061  0.004594  0.004067  ...  0.016992  0.013768  0.017690   \n3260 -0.014204 -0.000993 -0.000261  ... -0.006176 -0.000638  0.040115   \n3261  0.007418 -0.004663 -0.000718  ...  0.013192 -0.010128  0.001612   \n3262 -0.004269 -0.026597  0.000553  ...  0.012122 -0.013596 -0.003203   \n\n          1529      1530      1531      1532      1533      1534      1535  \n0    -0.024788 -0.033402  0.008030 -0.018713 -0.017624 -0.018405 -0.008645  \n1    -0.021798 -0.022683  0.014996 -0.028510 -0.023866 -0.010425 -0.032750  \n2    -0.009254 -0.000910  0.027406  0.007836 -0.013496  0.004219 -0.018068  \n3    -0.006639 -0.026271  0.040731  0.010892 -0.010331 -0.002601 -0.024528  \n4    -0.007897 -0.009853  0.027886 -0.009578 -0.001919 -0.000014 -0.008711  \n...        ...       ...       ...       ...       ...       ...       ...  \n3258 -0.009872 -0.003912  0.005459  0.007451 -0.022172 -0.002733 -0.008027  \n3259 -0.017493 -0.010069  0.020783 -0.004018 -0.019585 -0.022047 -0.018690  \n3260 -0.014889 -0.033241 -0.001455 -0.017211 -0.022380 -0.015090 -0.010606  \n3261  0.004137 -0.030025  0.021371 -0.022036 -0.016262  0.000142 -0.011779  \n3262 -0.027990 -0.052437 -0.001161 -0.010797 -0.005422 -0.009371 -0.050950  \n\n[3263 rows x 1537 columns]\nEpoch 1/200\n238/238 [==============================] - 1s 2ms/step - loss: 3.6765 - accuracy: 0.5714\nEpoch 2/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.6262 - accuracy: 0.6737\nEpoch 3/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.7273\nEpoch 4/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7559\nEpoch 5/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7358\nEpoch 6/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7771\nEpoch 7/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7636\nEpoch 8/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.7952\nEpoch 9/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7662\nEpoch 10/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7939\nEpoch 11/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8014\nEpoch 12/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7888\nEpoch 13/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7929\nEpoch 14/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8073\nEpoch 15/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7972\nEpoch 16/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7943\nEpoch 17/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7982\nEpoch 18/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.8120\nEpoch 19/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8175\nEpoch 20/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8002\nEpoch 21/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4256 - accuracy: 0.8119\nEpoch 22/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.8137\nEpoch 23/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8170\nEpoch 24/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4208 - accuracy: 0.8194\nEpoch 25/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4417 - accuracy: 0.8063\nEpoch 26/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4236 - accuracy: 0.8162\nEpoch 27/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4146 - accuracy: 0.8228\nEpoch 28/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.8179\nEpoch 29/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4205 - accuracy: 0.8189\nEpoch 30/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8143\nEpoch 31/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4028 - accuracy: 0.8262\nEpoch 32/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8228\nEpoch 33/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8204\nEpoch 34/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8189\nEpoch 35/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8135\nEpoch 36/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8254\nEpoch 37/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8233\nEpoch 38/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8106\nEpoch 39/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8271\nEpoch 40/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8203\nEpoch 41/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8219\nEpoch 42/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.8261\nEpoch 43/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4132 - accuracy: 0.8236\nEpoch 44/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4130 - accuracy: 0.8207\nEpoch 45/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4039 - accuracy: 0.8275\nEpoch 46/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.8166\nEpoch 47/200\n238/238 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8290\nEpoch 48/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3971 - accuracy: 0.8288\nEpoch 49/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3994 - accuracy: 0.8261\nEpoch 50/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8242\nEpoch 51/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4089 - accuracy: 0.8203\nEpoch 52/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4279 - accuracy: 0.8175\nEpoch 53/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3981 - accuracy: 0.8281\nEpoch 54/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8236\nEpoch 55/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8320\nEpoch 56/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8317\nEpoch 57/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8291\nEpoch 58/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3957 - accuracy: 0.8298\nEpoch 59/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8315\nEpoch 60/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8269\nEpoch 61/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8277\nEpoch 62/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8257\nEpoch 63/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3995 - accuracy: 0.8275\nEpoch 64/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3870 - accuracy: 0.8349\nEpoch 65/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4097 - accuracy: 0.8228\nEpoch 66/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8327\nEpoch 67/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.8245\nEpoch 68/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8357\nEpoch 69/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8300\nEpoch 70/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8299\nEpoch 71/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3957 - accuracy: 0.8296\nEpoch 72/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8291\nEpoch 73/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8311\nEpoch 74/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3859 - accuracy: 0.8334\nEpoch 75/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3934 - accuracy: 0.8304\nEpoch 76/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.8249\nEpoch 77/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8273\nEpoch 78/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3864 - accuracy: 0.8345\nEpoch 79/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3894 - accuracy: 0.8362\nEpoch 80/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8369\nEpoch 81/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8303\nEpoch 82/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3876 - accuracy: 0.8327\nEpoch 83/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3885 - accuracy: 0.8348\nEpoch 84/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3968 - accuracy: 0.8334\nEpoch 85/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3875 - accuracy: 0.8353\nEpoch 86/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4058 - accuracy: 0.8263\nEpoch 87/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3872 - accuracy: 0.8358\nEpoch 88/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3828 - accuracy: 0.8365\nEpoch 89/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3815 - accuracy: 0.8403\nEpoch 90/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3850 - accuracy: 0.8323\nEpoch 91/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8262\nEpoch 92/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3861 - accuracy: 0.8367\nEpoch 93/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3957 - accuracy: 0.8302\nEpoch 94/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3743 - accuracy: 0.8394\nEpoch 95/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8426\nEpoch 96/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8361\nEpoch 97/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8409\nEpoch 98/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3769 - accuracy: 0.8392\nEpoch 99/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3907 - accuracy: 0.8359\nEpoch 100/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3782 - accuracy: 0.8386\nEpoch 101/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3876 - accuracy: 0.8333\nEpoch 102/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8399\nEpoch 103/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3835 - accuracy: 0.8321\nEpoch 104/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3794 - accuracy: 0.8376\nEpoch 105/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3868 - accuracy: 0.8354\nEpoch 106/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8366\nEpoch 107/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8404\nEpoch 108/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3785 - accuracy: 0.8384\nEpoch 109/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3847 - accuracy: 0.8365\nEpoch 110/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3764 - accuracy: 0.8395\nEpoch 111/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3787 - accuracy: 0.8388\nEpoch 112/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8374\nEpoch 113/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8383\nEpoch 114/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3808 - accuracy: 0.8390\nEpoch 115/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8363\nEpoch 116/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8250\nEpoch 117/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8366\nEpoch 118/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3780 - accuracy: 0.8404\nEpoch 119/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8313\nEpoch 120/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3717 - accuracy: 0.8394\nEpoch 121/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8433\nEpoch 122/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8354\nEpoch 123/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3861 - accuracy: 0.8337\nEpoch 124/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3716 - accuracy: 0.8415\nEpoch 125/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8447\nEpoch 126/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3728 - accuracy: 0.8409\nEpoch 127/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8462\nEpoch 128/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3774 - accuracy: 0.8375\nEpoch 129/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8358\nEpoch 130/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8352\nEpoch 131/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3933 - accuracy: 0.8323\nEpoch 132/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3719 - accuracy: 0.8417\nEpoch 133/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8426\nEpoch 134/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8400\nEpoch 135/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3708 - accuracy: 0.8405\nEpoch 136/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8453\nEpoch 137/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8470\nEpoch 138/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8404\nEpoch 139/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8404\nEpoch 140/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8376\nEpoch 141/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.8311\nEpoch 142/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3752 - accuracy: 0.8489\nEpoch 143/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3760 - accuracy: 0.8411\nEpoch 144/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8424\nEpoch 145/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3747 - accuracy: 0.8418\nEpoch 146/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8384\nEpoch 147/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8449\nEpoch 148/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3865 - accuracy: 0.8327\nEpoch 149/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8467\nEpoch 150/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3716 - accuracy: 0.8386\nEpoch 151/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3722 - accuracy: 0.8415\nEpoch 152/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3739 - accuracy: 0.8417\nEpoch 153/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3778 - accuracy: 0.8409\nEpoch 154/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8422\nEpoch 155/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.8379\nEpoch 156/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3749 - accuracy: 0.8388\nEpoch 157/200\n238/238 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8397\nEpoch 158/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3667 - accuracy: 0.8482\nEpoch 159/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.8413\nEpoch 160/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8426\nEpoch 161/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3809 - accuracy: 0.8387\nEpoch 162/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8471\nEpoch 163/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3702 - accuracy: 0.8436\nEpoch 164/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3692 - accuracy: 0.8450\nEpoch 165/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8390\nEpoch 166/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8466\nEpoch 167/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8391\nEpoch 168/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8441\nEpoch 169/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8476\nEpoch 170/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8428\nEpoch 171/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8475\nEpoch 172/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3818 - accuracy: 0.8367\nEpoch 173/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8433\nEpoch 174/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8391\nEpoch 175/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8453\nEpoch 176/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8457\nEpoch 177/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3577 - accuracy: 0.8488\nEpoch 178/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8365\nEpoch 179/200\n238/238 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8400\nEpoch 180/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8453\nEpoch 181/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8461\nEpoch 182/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8443\nEpoch 183/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3720 - accuracy: 0.8418\nEpoch 184/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8455\nEpoch 185/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8512\nEpoch 186/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8528\nEpoch 187/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8485\nEpoch 188/200\n238/238 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8496\nEpoch 189/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8470\nEpoch 190/200\n238/238 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8482\nEpoch 191/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8450\nEpoch 192/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8453\nEpoch 193/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.8482\nEpoch 194/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8463\nEpoch 195/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8454\nEpoch 196/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8518\nEpoch 197/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8487\nEpoch 198/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3572 - accuracy: 0.8501\nEpoch 199/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3668 - accuracy: 0.8411\nEpoch 200/200\n238/238 [==============================] - 1s 2ms/step - loss: 0.3661 - accuracy: 0.8446\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7b72490b3ac0>"},"metadata":{}}]},{"cell_type":"code","source":"embedding_output = embedding_model.predict(dataset.test_sequences)\ntfidf_output = tfidf_model.predict(dataset.test_encoded_text)\nchatgpt_output = pd.read_csv(\"/kaggle/input/disaster-tweets-chatgpt-output/chatgpt_submission.csv\")\n\n# print the number of test cases, on which the combined model is >90% sure\nanswer = []\nfor i in range(len(dataset.test_data)):\n    tfidf_row = tfidf_output[i]\n    embedding_row = embedding_output[i]\n    chatgpt_answer = chatgpt_output.iloc[i]['target']\n\n    cnt = [0, 0]\n    cnt[0] += 1 if tfidf_row[0] > 0.9 else 0\n    cnt[1] += 1 if tfidf_row[1] > 0.9 else 1\n\n    cnt[0] += 1 if embedding_row[0] > 0.9 else 0\n    cnt[1] += 1 if embedding_row[1] > 0.9 else 0\n\n    if cnt[0] != cnt[1]:\n        answer.append(1 if cnt[0] > cnt[1] else 0)\n    else:\n        answer.append(chatgpt_answer)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T23:04:13.470614Z","iopub.execute_input":"2023-06-23T23:04:13.471866Z","iopub.status.idle":"2023-06-23T23:04:17.226773Z","shell.execute_reply.started":"2023-06-23T23:04:13.471828Z","shell.execute_reply":"2023-06-23T23:04:17.225606Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 1s 8ms/step\n102/102 [==============================] - 0s 4ms/step\n[0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = pd.DataFrame({\n    'id': test_data['id'],\n    'target': answer\n})\n\npredictions.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:02:20.623211Z","iopub.execute_input":"2023-06-23T20:02:20.623601Z","iopub.status.idle":"2023-06-23T20:02:20.635318Z","shell.execute_reply.started":"2023-06-23T20:02:20.623564Z","shell.execute_reply":"2023-06-23T20:02:20.634056Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"import openai\n\nopenai.api_key = \"\"\n\ndef get_chatgpts_opinion(tweet, model_name=\"gpt-3.5-turbo\"):\n    chat_completion = openai.ChatCompletion.create(\n    model=model_name,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Output a single letter, 1 if the following tweet is about a real disaster and 0 if not: \" + tweet.replace(\"\\n\", \" \")\n        }])\n    return chat_completion.choices[0].message.content","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:11:11.521705Z","iopub.execute_input":"2023-06-23T19:11:11.522088Z","iopub.status.idle":"2023-06-23T19:11:11.528655Z","shell.execute_reply.started":"2023-06-23T19:11:11.522058Z","shell.execute_reply":"2023-06-23T19:11:11.527360Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Print sample tweets on which ChatGPT is makings mistakes\nimport time\n\nindex = 0\ncnt_mistakes = 0\nwhile index < len(dataset.train_data) and cnt_mistakes < 10:\n    try:\n        text = dataset.train_data.iloc[index]['text']\n        expected_output = dataset.train_target_data.iloc[index]\n        output = get_chatgpts_opinion(text)\n        index += 1\n        \n        if int(expected_output) != int(output):\n            print(dataset.train_data.iloc[index])\n            print(\"Expected output: {}, Real output: {}\\n\\n\".format(expected_output, output))\n            cnt_mistakes += 1\n    except:\n        print(\"Failed, will try again soon ...\")\n        time.sleep(5)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:17:29.233973Z","iopub.execute_input":"2023-06-23T19:17:29.234328Z","iopub.status.idle":"2023-06-23T19:18:26.311387Z","shell.execute_reply.started":"2023-06-23T19:17:29.234303Z","shell.execute_reply":"2023-06-23T19:18:26.310319Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"id                                                         18\nkeyword                                                   NaN\nlocation                                                  NaN\ntext        #raining #flooding #Florida #TampaBay #Tampa 1...\ntarget                                                      1\nName: 12, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                               19\nkeyword                                         NaN\nlocation                                        NaN\ntext        #Flood in Bago Myanmar #We arrived Bago\ntarget                                            1\nName: 13, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                                         77\nkeyword                                                ablaze\nlocation                                              Anaheim\ntext        Police: Arsonist Deliberately Set Black Church...\ntarget                                                      1\nName: 53, dtype: object\nExpected output: 0, Real output: 1\n\n\nid                                                         80\nkeyword                                                ablaze\nlocation                                         South Africa\ntext        TRUCK ABLAZE : R21. VOORTREKKER AVE. OUTSIDE O...\ntarget                                                      1\nName: 56, dtype: object\nExpected output: 1, Real output: 0\n\n\nFailed, will try again soon ...\nid                                                         98\nkeyword                                              accident\nlocation                                      Santa Clara, CA\ntext        Accident center lane blocked in #SantaClara on...\ntarget                                                      1\nName: 69, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                                        107\nkeyword                                              accident\nlocation                                       North Carolina\ntext        I-77 Mile Marker 31 South Mooresville  Iredell...\ntarget                                                      1\nName: 74, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                                        113\nkeyword                                              accident\nlocation                                       North Carolina\ntext        I-77 Mile Marker 31 to 40 South Mooresville  I...\ntarget                                                      1\nName: 78, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                                        117\nkeyword                                              accident\nlocation                                                  NaN\ntext        mom: 'we didn't get home as fast as we wished'...\ntarget                                                      0\nName: 80, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                                      131\nkeyword                                            accident\nlocation                                     Wilmington, NC\ntext        ;ACCIDENT PROPERTY DAMAGE; PINER RD/HORNDALE DR\ntarget                                                    1\nName: 89, dtype: object\nExpected output: 1, Real output: 0\n\n\nid                                                     132\nkeyword                                           accident\nlocation                                               NaN\ntext        ???? it was an accident http://t.co/Oia5fxi4gM\ntarget                                                   0\nName: 90, dtype: object\nExpected output: 1, Real output: 0\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"wrong_indexes = [12, 13, 53, 56, 69, 74, 78, 80, 89, 90]\nfor index in wrong_indexes:\n    print(dataset.train_data.iloc[index]['text'])\n    print(\"REAL\" if dataset.train_target_data.iloc[index] == 1 else \"FAKE\")\n    print(\"\\n\\n\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:21:58.792307Z","iopub.execute_input":"2023-06-23T19:21:58.792650Z","iopub.status.idle":"2023-06-23T19:21:58.800495Z","shell.execute_reply.started":"2023-06-23T19:21:58.792610Z","shell.execute_reply":"2023-06-23T19:21:58.799561Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"#raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count \nREAL\n\n\n\n\n#Flood in Bago Myanmar #We arrived Bago\nREAL\n\n\n\n\nPolice: Arsonist Deliberately Set Black Church In North CarolinaåÊAblaze http://t.co/pcXarbH9An\nREAL\n\n\n\n\nTRUCK ABLAZE : R21. VOORTREKKER AVE. OUTSIDE OR TAMBO INTL. CARGO SECTION. http://t.co/8kscqKfKkF\nREAL\n\n\n\n\nAccident center lane blocked in #SantaClara on US-101 NB before Great America Pkwy #BayArea #Traffic http://t.co/pmlOhZuRWR\nREAL\n\n\n\n\nI-77 Mile Marker 31 South Mooresville  Iredell Vehicle Accident Ramp Closed at 8/6 1:18 PM\nREAL\n\n\n\n\nI-77 Mile Marker 31 to 40 South Mooresville  Iredell Vehicle Accident Congestion at 8/6 1:18 PM\nREAL\n\n\n\n\nmom: 'we didn't get home as fast as we wished' \nme: 'why is that?'\nmom: 'there was an accident and some truck spilt mayonnaise all over ??????\nFAKE\n\n\n\n\n;ACCIDENT PROPERTY DAMAGE; PINER RD/HORNDALE DR\nREAL\n\n\n\n\n???? it was an accident http://t.co/Oia5fxi4gM\nFAKE\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up and test the OpenAI API\nimport openai\nimport time\n\nwhile len(chatgpt_output) != len(dataset.test_data):\n    try:\n        index = len(chatgpt_output)\n        text = dataset.test_data.iloc[index]['text']\n        chatgpt_output.append(1 if get_chatgpts_opinion(text) == '1' else 0)\n        if len(chatgpt_output) % 20 == 0:\n            print(\"Finished with {} tweets ...\".format(len(chatgpt_output)))\n    except:\n        print(\"Failed, will try again soon ...\")\n        print(\"Current output length: {}\".format(len(chatgpt_output)))\n        time.sleep(5)\n\nprint(len(chatgpt_output))\nprint(chatgpt_output[:10])\nprint(dataset.test_data.head(10)['text'])","metadata":{"execution":{"iopub.status.busy":"2023-06-23T00:03:16.339973Z","iopub.execute_input":"2023-06-23T00:03:16.340376Z","iopub.status.idle":"2023-06-23T00:12:21.580083Z","shell.execute_reply.started":"2023-06-23T00:03:16.340349Z","shell.execute_reply":"2023-06-23T00:12:21.578905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tfidf_output = tfidf_model.predict(dataset.test_encoded_text)\n\ncnt_correct = 0\nfor i, x in enumerate(chatgpt_output):\n    y = 0 if tfidf_output[i, 0] > tfidf_output[i, 1] else 1\n    if x == y:\n        cnt_correct += 1\n        \n# print(chatgpt_output)\n# print(tfidf_output[i, 0])\n        \nprint(cnt_correct / len(chatgpt_output))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T00:13:04.564277Z","iopub.execute_input":"2023-06-23T00:13:04.564663Z","iopub.status.idle":"2023-06-23T00:13:04.576426Z","shell.execute_reply.started":"2023-06-23T00:13:04.564635Z","shell.execute_reply":"2023-06-23T00:13:04.575092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legacy_chatgpt_output = chatgpt_output\nprint(legacy_chatgpt_output)\nprint(len(legacy_chatgpt_output))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T00:12:54.036063Z","iopub.execute_input":"2023-06-23T00:12:54.037151Z","iopub.status.idle":"2023-06-23T00:12:54.043333Z","shell.execute_reply.started":"2023-06-23T00:12:54.037113Z","shell.execute_reply":"2023-06-23T00:12:54.042124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.DataFrame({\n    'id': test_data['id'],\n    'target': chatgpt_output\n})\n\npredictions.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T00:13:09.648667Z","iopub.execute_input":"2023-06-23T00:13:09.649089Z","iopub.status.idle":"2023-06-23T00:13:09.670099Z","shell.execute_reply.started":"2023-06-23T00:13:09.649059Z","shell.execute_reply":"2023-06-23T00:13:09.668817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}